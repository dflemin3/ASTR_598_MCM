{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "\n",
    "#Typical plot parameters that make for pretty plots\n",
    "mpl.rcParams['figure.figsize'] = (8,8)\n",
    "mpl.rcParams['font.size'] = 15.0\n",
    "mpl.rc('text', usetex='true') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(int((time.time()%1)*1.0e8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Integration\n",
    "\n",
    "---\n",
    "\n",
    "Useful to integrate when your dimension d > 10 or so.\n",
    "\n",
    "If you sample function with N points, the error scales as error (variance) $\\sim 1/\\sqrt{N}$.  Slow, but guarenteed.  Make sure to vary point number, like use N and 2N when doing calculations for a good error comparison.  Also, you should run multiple independent simulations (different RNG seeds, of course!) to get a better answer, more robust error.  To do this, run multiple copies on different cores (easy to parallelize!), can plot distribution of answers to get answer, error from width of distribution.  We expect this error to decrease as the error equation given above.\n",
    "\n",
    "Pros:\n",
    "```\n",
    "1. Good for large number of dimensions\n",
    "2. error ~ 1/sqrt(N)\n",
    "3. easy to run multiple independent simulations for comparison/error estimate\n",
    "4. easy to parallelize\n",
    "5. easy to check point (save state if calculation is interupted)\n",
    "    -Ex: every x steps, print out RNG seed, point information to some file\n",
    "```\n",
    "\n",
    "Cons:\n",
    "```\n",
    "1. Can be slow for large N\n",
    "2. Can require large N to beat down errors\n",
    "```\n",
    "\n",
    "Ex. Estimating pi using Monte Carlo Integration\n",
    "```\n",
    "1. Draw random x, y from [0,1] uniformly\n",
    "2. Check to see if it's within the circle (if x^2 + y^2 < 1)\n",
    "3. Count total points, total points within circle\n",
    "4: (area of circle quadrant)/(area of 1 by 1 square) == (number of points within circle)/(total number of points)\n",
    "```\n",
    "\n",
    "Algorithms like this are really easy to generalize to a higher dimension.  Imagine some 10-sphere of \"radius\" 1.  Finding it's 10-volume (whatever that is) via Monte Carlo integration uses the same scheme as above but the if statement becomes\n",
    "```\n",
    "if x1^2 + x2^2 + ... + x10^2 < 1:\n",
    "    area_count++\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def volume4Dsphere(radius, N):\n",
    "    \"\"\"\n",
    "    Perform a monte carlo integration to compute the radius of a 4d \"sphere\"\n",
    "    using N samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sanity checks\n",
    "    if radius <= 0.0:\n",
    "        print(\"ERROR: Radius must be greater than 0.\")\n",
    "        return -1\n",
    "    if N <= 0:\n",
    "        print(\"ERROR: Number of integration points must be greater than 0\")\n",
    "        return -1\n",
    "    if N > 1.0e6:\n",
    "        print(\"My computer can't handle this!\")\n",
    "        return -1\n",
    "    \n",
    "    # Draw 4 random deviates from 0 to radius\n",
    "    # These sample 1/16 of sphere volume... like the equivalent of the 1st quadrant of the sphere\n",
    "    # Volume of \"1st quadrant\" goes as 16*radius^4 (like )\n",
    "    x = np.random.uniform(low=0.0, high=radius, size=N)\n",
    "    y = np.random.uniform(low=0.0, high=radius, size=N)\n",
    "    z = np.random.uniform(low=0.0, high=radius, size=N)\n",
    "    w = np.random.uniform(low=0.0, high=radius, size=N)\n",
    "\n",
    "    return 16.0*np.power(radius,4.0)*np.sum(x**2 + y**2 + z**2 + w**2 <= radius**2.0)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trueVolume(radius):\n",
    "    \"\"\"\n",
    "    Returns the true volume of a 4d sphere using the formula from\n",
    "    https://en.wikipedia.org/wiki/N-sphere\n",
    "    \"\"\"\n",
    "    return np.power(np.pi,2.0)*np.power(radius,4.)/gamma(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000752.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius = 30.0\n",
    "volume4Dsphere(radius,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997189.78244119"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueVolume(radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis-Hastings Algorithm\n",
    "### The meat and potatoes of MCMC\n",
    "\n",
    "https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\n",
    "\n",
    "or \n",
    "\n",
    "http://www.life.illinois.edu/dietze/Lectures2012/Lesson12_Metropolis.pdf\n",
    "\n",
    "Problem: Transformation method only works in 1D and the rejection method can be very inefficient.\n",
    "\n",
    "Solution:  Sample around some x0 where you try to find the regions of maximal probability to make good usage of finite computer time.\n",
    "\n",
    "---\n",
    "\n",
    "Authors were simulating hard sphere gas physics.  Had a box with periodic boundary conditions and were seeing how the gas particles moved.  Use some maximum step size and drew random numbers to update positions to sample important configuration since we don't care about unlikely states.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "---\n",
    "\n",
    "Always go downhill, sometimes go uphill (relative to -log probability minima) to prevent you from always getting stuck in local minima\n",
    "\n",
    "```\n",
    "For the case of gas particles with some interaction between them that gives the energy\n",
    "\n",
    "1) We calculate the change in energy caused by the trial move\n",
    "\n",
    "2) If Delta_E < 0: # Always go downhill\n",
    "       accept move, put particle in new position\n",
    "       X = X_new\n",
    "       Y = Y_new\n",
    "   else: # delta_E >= 0... sometimes accept uphill move\n",
    "       get a random number U3 between 0 and 1\n",
    "       if(U3 < exp(-Delta_E/kT)): # exp(-Delta_E/kT) is 0 <= P(Delta_E) <= 1: acceptance probability\n",
    "           # accept the move\n",
    "           X = X_new\n",
    "           Y = Y_new\n",
    "       else:\n",
    "           pass # do nothing X=X, Y=Y, configuration is the same\n",
    "           \n",
    "we compute new position via X_old + alpha*U1\n",
    "\n",
    "where alpha is the step size and U1 is a random deviate from [0,1]\n",
    "```\n",
    "\n",
    "Need to choose step size to make sure you sample the distribution.\n",
    "\n",
    "Need to vary...\n",
    "```\n",
    "1) system size\n",
    "2) Monte Carlo step size (x)\n",
    "3) Number of steps\n",
    "4) Starting configuration\n",
    "5) Initial discarded steps\n",
    "    - Do some initial steps, throw them out so your starting condition is reasonable.\n",
    "    - This is the \"burn in\" or the \"equilibrating the system\"\n",
    "        - If we started with bad initial condition, burn in can come to reasonable value\n",
    "          so it doesn't screw up the computation too much\n",
    "6) Vary how high (y) chain can jump... like acceptance ratio (Temperature T in above example)\n",
    "```\n",
    "to ensure your simulation is robust.  If you get similar results after varying everything, the result is likely solid.\n",
    "\n",
    "### Averaging\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "<F> = \\frac{1}{N} \\sum_{y=1}^N F_j\n",
    "$$\n",
    "\n",
    "using different simulation results.\n",
    "\n",
    "### Autocorrelation\n",
    "\n",
    "---\n",
    "\n",
    "At some step t, look at a quantity c and then later, average it\n",
    "\n",
    "$$\n",
    "<c(t)c(t + \\tau)>\n",
    "$$\n",
    "if it's small, its better.\n",
    "\n",
    "\n",
    "From http://stats.stackexchange.com/questions/110268/why-is-it-desirable-to-have-low-auto-correlation-in-mcmc:\n",
    "```\n",
    "Autocorrelation is a measure of how much the value of a signal correlates to other values of that signal at different points in time. In the context of MCMC, autocorrelation is a measure of how independent different samples from your posterior distribution are â€“ lower autocorrelation indicating more independent results.\n",
    "\n",
    "When you have high autocorrelation the samples you've drawn don't accurately represent the posterior distribution and therefore don't provide as meaningful information for the solution to the problem. In other words, lower autocorrelation means higher efficiency in your chains and better estimates. A general rule would be that the lower your autocorrelation, the less samples you need for the method to be effective (but that might be oversimplifying).\n",
    "```\n",
    "\n",
    "But warning, you could have a low autocorrelation and be stuck in a local minima, so vary all the things mentioned above!\n",
    "\n",
    "### Error estimates\n",
    "\n",
    "---\n",
    "\n",
    "Like other MCMCs, can use independent simulations to calculate variance for error bars\n",
    "\n",
    "### System size scaling\n",
    "\n",
    "---\n",
    "\n",
    "Examine how parameters vary with system size.  For example, specific heat function becomes more peaked with system size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example: Traveling Salesman Problem\n",
    "\n",
    "---\n",
    "\n",
    "Situation: Suppose you have some map of the US with a bunch of cities (nodes) and roads (edges) connecting them.  \n",
    "\n",
    "Problem: How do we visit each city once while minimizing the length travelled?\n",
    "\n",
    "This isn't as much as a problem for actual salemen as it is from things like shipping, airline travel, or electicity moving across a circuit.\n",
    "\n",
    "You cannot solve this problem by generating all possible combinations.  For continental state capitols when you start in one, the number of combinations is 47!/2 which is a huge amount for small number of capitols.\n",
    "\n",
    "### Simulated Annealing\n",
    "\n",
    "---\n",
    "\n",
    "First, label cities for simplicity\n",
    "```\n",
    "Inits:\n",
    "1) Start with some random tour with length L\n",
    "2) Pick some \"temperature\" larger than L\n",
    "    We have some factor exp(-Delta_L/T) that governs how often we can go uphill\n",
    "Loop:\n",
    "3) Get the new step (trial configuration)\n",
    "    - For example, select 2 random cities, flip sequence\n",
    "4) Use Metropolis Algorithm \n",
    "    - If L goes less, always accept\n",
    "    - If it increases, accept it with P = exp(-Delta_L/T)\n",
    "    - Back to 3) to get new trial step\n",
    "5) After some N Metropolis Algorithm step, set L = L - Delta_L (Reduce temp step)\n",
    "\n",
    "To clarify, there are two loops:  Inner Metropolis loop then outer temperature loop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
